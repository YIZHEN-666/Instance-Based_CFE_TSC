{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in some Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.4.1\n",
      "Eager execution enabled:  False\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from tslearn.neighbors import NearestNeighbors, KNeighborsTimeSeries\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv1D, GlobalAveragePooling1D, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import function\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from counterfactual_utils import ucr_data_loader, label_encoder\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "#setting a random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and classifier example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, X_test, y_test = ucr_data_loader(str('ecg200'))\n",
    "#y_train, y_test = label_encoder(y_train, y_test)\n",
    "#\n",
    "#model =load_model('ecg200_best_model.hdf5')\n",
    "#y_pred = model.predict(X_test)\n",
    "#y_pred = np.argmax(y_pred, axis=1)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we want to be able to specify what our counterfactual target is. This should be different to the predicted label of the base classifier. Also lets specify the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_(label):\n",
    "    if label == 0:\n",
    "        counter = 1\n",
    "    elif label == 1:\n",
    "        counter = 0\n",
    "    return counter\n",
    "\n",
    "\n",
    "def dist_mad(query, cf):\n",
    "    manhat = np.abs(query-cf)\n",
    "    mad = stats.median_absolute_deviation(X_train)\n",
    "    return np.sum((manhat/mad).flatten())\n",
    "\n",
    "def loss_function_mad(x_dash):\n",
    "    target = target_(example_label)\n",
    "    L = lamda*(model.predict(x_dash.reshape(1,-1,1))[0][target] - 1)**2 + \\\n",
    "    dist_mad(x_dash.reshape(1,-1,1), query)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking target works & mad distance works\n",
    "#y_pred[0], target_(y_pred[0]), dist_mad(X_test[0], X_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wachter Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wachter_Counterfactual(instance, lambda_init):\n",
    "\n",
    "    min_edit_cf = []\n",
    "    \n",
    "    global lamda\n",
    "    global dist_mad\n",
    "    global loss_function_mad\n",
    "    global example_label\n",
    "    global query\n",
    "\n",
    "    \n",
    "    pred_threshold = 0.5\n",
    "\n",
    "    # initial conditions\n",
    "    lamda = lambda_init\n",
    "    x0 = X_test[instance].reshape(1,-1,1) # initial guess for cf\n",
    "    query = X_test[instance].reshape(1,-1,1)\n",
    "\n",
    "    example_label = y_pred[instance]\n",
    "\n",
    "    res = minimize(loss_function_mad, x0.reshape(1,-1), method='nelder-mead', options={'maxiter':10, 'xatol': 50, 'adaptive': True})\n",
    "    cf = res.x.reshape(1,-1,1)\n",
    "\n",
    "    target = target_(y_pred[instance])\n",
    "    prob_target = model.predict(cf)[0][target]\n",
    "\n",
    "\n",
    "    i=0\n",
    "    while prob_target < pred_threshold:\n",
    "\n",
    "\n",
    "        lamda = lambda_init*(1+0.5)**i\n",
    "        x0 = cf\n",
    "        res = minimize(loss_function_mad, x0.reshape(1,-1), method='nelder-mead', options={'maxiter':10, 'xatol': 50, 'adaptive': True})\n",
    "        cf = res.x.reshape(1,-1,1)\n",
    "        prob_target = model.predict(cf)[0][target]\n",
    "        i += 1\n",
    "        if i == 500:\n",
    "            print('Error condition not met after',i,'iterations')\n",
    "            break\n",
    "\n",
    "    min_edit_cf.append(cf[0])\n",
    "\n",
    "    \n",
    "    return min_edit_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dataset in ['coffee', 'ecg200', 'gunpoint', 'chinatown']:\n",
    "    \n",
    "#    X_train, y_train, X_test, y_test = ucr_data_loader(str(dataset))\n",
    "#    y_train, y_test = label_encoder(y_train, y_test)\n",
    "    \n",
    "#    model =load_model(str(dataset)+'_best_model.hdf5')\n",
    "#    y_pred = model.predict(X_test)\n",
    "#    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    \n",
    "#    counterfactual_set = []\n",
    "    \n",
    "#    for instance in range(len(X_test)):\n",
    "#        counterfactual_set.append(Wachter_Counterfactual(instance,lambda_init=0.1)[0])\n",
    "        \n",
    "#    np.array(counterfactual_set)\n",
    "#    np.save(str(dataset) + '_wachter_cf', np.array(counterfactual_set))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
